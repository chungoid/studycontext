# Study-Guide Generator - Developer Guide\n\n**Version:** 0.1.0\n\n## 1. Introduction\n\nThis guide provides instructions for developers working on the Study-Guide Generator project. It covers setup, dependencies, running the tool, and executing tests.\n\n## 2. Project Structure\n\n```\nstudycontext/\n├── .github/\n│   └── workflows/\n│       └── ci.yml\n├── docs/\n│   └── developer_guide.md\n├── src/\n│   ├── __init__.py\n│   ├── main.py\n│   ├── llm_chain/\n│   │   ├── __init__.py\n│   │   ├── chain.py\n│   │   └── prompts/\n│   │       ├── __init__.py\n│   │       ├── extract_concepts_prompt.txt\n│   │       └── generate_qa_prompt.txt\n│   ├── output_formatter/\n│   │   ├── __init__.py\n│   │   └── formatter.py\n│   └── transcript_parser/\n│       ├── __init__.py\n│       └── parser.py\n├── tests/\n│   ├── __init__.py\n│   ├── test_chain.py\n│   ├── test_formatter.py\n│   └── test_parser.py\n│   └── test_prompts_for_chain_tests/ # Created by test_chain.py module fixture\n│       └── test_prompt.txt\n├── .gitignore\n├── README.md\n├── requirements.txt\n└── status.md\n```\n\n-   `.github/workflows/`: Contains GitHub Actions CI configuration.\n-   `docs/`: Project documentation.\n-   `src/`: Source code for the application.\n    -   `main.py`: CLI entry point and orchestration logic.\n    -   `transcript_parser/`: Module for reading, cleaning, and segmenting transcripts.\n    -   `llm_chain/`: Module for interacting with the LLM (OpenAI API).\n        -   `prompts/`: Directory for storing LLM prompt templates.\n    -   `output_formatter/`: Module for formatting the generated study guide.\n-   `tests/`: Unit tests for the project. Contains a sub-directory `test_prompts_for_chain_tests` created by a `pytest` fixture in `test_chain.py` for its own prompt loading tests.\n-   `requirements.txt`: Lists project dependencies.\n-   `status.md`: Tracks project progress.\n\n## 3. Setup and Dependencies\n\n### 3.1. Prerequisites\n\n-   Python 3.10 or higher.\n-   `pip` (Python package installer).\n-   Git (for version control).\n\n### 3.2. Installation\n\n1.  **Clone the repository (if you haven\'t already):**\n    ```bash\n    git clone <repository_url>\n    cd studycontext\n    ```\n\n2.  **Create and activate a virtual environment (recommended):**\n    ```bash\n    python -m venv venv\n    source venv/bin/activate  # On Windows: venv\\Scripts\\activate\n    ```\n\n3.  **Install dependencies:**\n    ```bash\n    pip install -r requirements.txt\n    ```\n    This will install `openai`, `pytest`, `black`, `flake8`, and `mypy`.\n\n### 3.3. Environment Variables\n\nTo interact with the OpenAI API, you need to set the `OPENAI_API_KEY` environment variable.\n\n```bash\nexport OPENAI_API_KEY=\"your_actual_openai_api_key\"\n```\n\n**Note:** For running tests, a dummy API key (`test_dummy_key`) is passed by the CI script. For local testing where the client might be initialized (even if API calls are mocked), ensure this variable is set, or use a dummy value if you are sure no actual API calls will be made by the tests you are running. The unit tests in `tests/test_chain.py` are designed to mock out actual API calls but still require the key to be set for the client initialization logic within the module to pass or be correctly patched.\n\n## 4. Running the Tool (CLI)\n\nThe main entry point for the CLI tool is `src/main.py`.\n\n**Synopsis:**\n\n```bash\npython src/main.py <transcript_file_path> [-o <output_file_path>] [--words_per_segment <count>]\n```\n\n**Arguments:**\n\n-   `transcript_file_path`: (Required) Path to the plain text lecture transcript file.\n-   `-o <output_file_path>`, `--output_file <output_file_path>`: (Optional) Path to save the generated study guide. If not provided, the output will be printed to the console.\n-   `--words_per_segment <count>`: (Optional) Approximate number of words for each text segment sent to the LLM. Defaults to 500.\n\n**Example:**\n\n```bash\n# To process a transcript and print to console\npython src/main.py path/to/your/transcript.txt\n\n# To process a transcript and save to a file\npython src/main.py path/to/your/transcript.txt -o path/to/your/study_guide.txt\n\n# To specify segment length\npython src/main.py path/to/your/transcript.txt --words_per_segment 300\n```\n\n## 5. Running Linters and Formatters\n\n### 5.1. Black (Formatter)\n\nTo check formatting (without making changes):\n```bash\nblack --check --diff .\n```\n\nTo apply formatting:\n```bash\nblack .\n```\n\n### 5.2. Flake8 (Linter)\n\n```bash\nflake8 .\n```\n\n### 5.3. MyPy (Type Checker)\n\n```bash\nmypy src/\n```\n(The CI pipeline uses `mypy src/ --ignore-missing-imports`)\n\n## 6. Running Tests\n\nTests are written using `pytest`.\n\n1.  **Ensure `OPENAI_API_KEY` is set in your environment**, even if it\'s a dummy value like \"test\_key\". The test suite for `llm_chain` expects this for client initialization code paths, although actual API calls are mocked.\n\n2.  **Navigate to the project root directory.**\n\n3.  **Run all tests:**\n    ```bash\n    pytest\n    ```\n\n4.  **Run tests with coverage:**\n    ```bash\n    pytest --cov=src\n    ```\n    This will output a coverage report to the console. HTML and XML reports are also generated by the CI pipeline (in `htmlcov/` and `coverage.xml` respectively if you run with the same flags: `pytest tests/ --cov=src --cov-report=xml --cov-report=html`).\n\n## 7. CI Pipeline\n\nThe project uses GitHub Actions for Continuous Integration. The workflow is defined in `.github/workflows/ci.yml`. It automatically runs linters, formatters, type checks, and tests on pushes and pull requests to the `main` branch.\n\n 